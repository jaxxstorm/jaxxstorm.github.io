<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Kubernetes Networking - Part 1 | lbr.</title>

<meta name="description" content="Engineering, DevOps & Cloud Computing
">
<meta name="keywords" content="kubernetes, flannel, calico">
<link rel="canonical" href="/blog/2017/02/15/kubernetes-networking-part1.html">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-34865189-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-34865189-1');
</script>


<!--Feature assets-->
<!--Bootstrap JS-->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>

<!--Font Awesome-->
<link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css" integrity="sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p" crossorigin="anonymous"/>

<!--Highlight.js-->
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.3.2/build/styles/default.min.css">
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.3.2/build/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!--Main assets-->
<link rel="icon" type="image/jpeg" href="/favicon.png"/>
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<link rel="stylesheet" href="/assets/css/main.css">
</head>
<body>
<div class="wrapper">
<header class="header">
<div class="navigation">

<a href="/" class="logo">lbr.</a>

<ul class="menu">
<li class="menu__entry"><a href="/">about</a></li>
<li class="menu__entry"><a href="/projects">projects</a></li>
<li class="menu__entry"><a href="/blog">blog</a></li>
</ul>
</div>
<ul class="social-links">

<a href="mailto:/contact@leebriggs.co.uk" class="social-links__entry" target="_blank">
<i class="fas fa-envelope-square"></i>
</a>


<a href="https://github.com//jaxxstorm" class="social-links__entry" target="_blank">
<i class="fab fa-github"></i>
</a>


<a href="https://linkedin.com/in//briggsl" class="social-links__entry" target="_blank">
<i class="fab fa-linkedin-in"></i>
</a>

</ul>
</header>

<br>
<br>
<h1 class="post-title">
    <div class="post-title__text">Kubernetes Networking - Part 1</div>
</h1>
<p class="post-title__subtitle">Published Feb 15, 2017  by <a href="https://leebriggs.co.uk/">Lee Briggs<a><br />


    <span class="badge badge-info">#kubernetes</span>

    <span class="badge badge-info">#flannel</span>

    <span class="badge badge-info">#calico</span>

<hr>
<br>
<p>I have some problems with Kubernetes.</p>

<p>It’s a fantastic tool that is revolutionizing the way we do things at $work. However, because of its code complexity, and the vast number of features, plugins, addons and options, the documentation isn’t getting the job done.</p>

<p>The other issue is that too many of the “Getting Started” tutorials gloss over the parts that you <em>actually</em> need to know. Let’s take a look at the <a href="https://kubernetes.io/docs/getting-started-guides/kubeadm/">kubeadm</a> page, for example. In the networking section, it says this:</p>

<blockquote>
  <p>You can install a pod network add-on with the following command:  kubectl apply -f <add-on.yaml></add-on.yaml></p>
</blockquote>

<p>Now, the ease of this is fantastic. You can initialize your network super easily, and if you’re playing around with minikube or some other small setup, this really takes the pain out of getting started.</p>

<p>However, take a look at the full <a href="https://kubernetes.io/docs/admin/networking/">networking documentation</a> page. If things go wrong, are you going to have any idea what’s going on here? Do you feel comfortable running this in production?</p>

<p>I certainly didn’t, so for the past week or so, I’ve been learning how all this works. I’m going to detail all this in two parts. First, I’m going to explain in sysadmin (ie I try to avoid network gear at all costs) terms how kubernetes approaches networking. Most of the information here is in the earlier linked networking doc, but I’m going to put it in my own words.</p>

<p>The next post will be specifically about my chosen pod network provider, <a href="https://projectcalico.org">Calico</a> and how it interacts with your OS and containers.</p>

<p><strong>Disclaimer:</strong> I’m not an expert on networking by any stretch of the imagination. If any of this is wrong, please <a href="https://github.com/jaxxstorm/jaxxstorm.github.io">send a pull request</a></p>

<h1 id="basics">Basics</h1>

<p>There’s a lot of words on the earlier networking page. I’m going to sum it up a bit differently. <em>In order for Kubernetes to work, every pod needs to have its own IP address like a VM</em></p>

<p>This is in direct conflict with the default setup of standalone Docker. By default Docker gives itself a private IP address on the host. It creates an  bridge interface, <code class="language-plaintext highlighter-rouge">docker0</code> and then grabs an IP, usually something like <code class="language-plaintext highlighter-rouge">172.17.0.1</code></p>

<p>All the containers then get ` veth` interface so they can talk to each other. The problem here is that they can only talk to containers on the same host. In order to talk to containers on <em>other</em> hosts, they have to start port mapping on the host. Anyone who’s had to deal with this at scale knows its an exercise in futility.</p>

<p>So, back to Kubernetes. Every pod gets an IP right? How does it do that?</p>

<p>Well, the pod network mentioned above (you know, that yaml file you downloaded and blindly installed) is usually the thing that controls that. The way it does that varies slightly depending on your chosen network provider (whether it be flannel, weave, calico etc) but the basics remain essentially the same.</p>

<h1 id="an-ip-for-every-container">An IP for every container</h1>

<p>When the pod network starts up, you usually have to provide a relatively large subnet for configuration. <a href="https://coreos.com/flannel/docs/latest/flannel-config.html">The CoreOS flannel docs</a>, for example suggest using the subnet ` 10.1.0.0/16`. You’ll see why this is so large in a moment.</p>

<p>The subnet is usually predetermined and needs to be stored somewhere, which increasingly seems to be etcd. You usually have to set this before launching the pod network, and it’s often stored in the kubernetes manifest. If you look at the <a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml">kube-flannel</a> manifest, you’ll see this:</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">kube-flannel-cfg</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">tier</span><span class="pi">:</span> <span class="s">node</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">flannel</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="s">cni-conf.json</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">{</span>
      <span class="s">"name": "cbr0",</span>
      <span class="s">"type": "flannel",</span>
      <span class="s">"delegate": {</span>
        <span class="s">"isDefaultGateway": true</span>
      <span class="s">}</span>
    <span class="s">}</span>
  <span class="s">net-conf.json</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">{</span>
      <span class="s">"Network": "10.244.0.0/16",</span>
      <span class="s">"Backend": {</span>
        <span class="s">"Type": "vxlan"</span>
      <span class="s">}</span>
    <span class="s">}</span></code></pre></figure>

<p>This is simple, it’s setting a <a href="https://github.com/containernetworking/cni">CNI</a> config, which will then be shipped off to etcd to be stored for safekeeping.</p>

<p>When a container comes online, it looks at the preprovided subnet, and will give itself an IP address from the subnet provided.</p>

<h1 id="connectivity">Connectivity</h1>

<p>Now, just because there’s a subnet assigned, doesn’t mean there’s <em>connectivity</em>. And if you remember previously, pods need to have connectivity, even across different hosts.</p>

<p>This is important, and is something you should ensure works before you start deploying this to Kubernetes. From kubernetes node, <em>you should be able to get icmp traffic any pod on your network</em> and you should <em>also be able to ping any pod ip from another pod</em>. It depends on your pod network how this work. With <a href="https://github.com/coreos/flannel">flannel</a> for example, you get an interface added on each host (usually <code class="language-plaintext highlighter-rouge">flannel0</code>) and the connectivity is provided across a layer2 overlay network using vxlan. This is relatively simple, but there are some performance penalties. Calico uses a more elegant but more complicated solution which I’ll cover in much more detail in the next post.</p>

<p>In the meantime, let’s look at what a working config looks like in action.</p>

<h2 id="testing-connectivity">Testing Connectivity</h2>

<p>I’ve deployed the guestbook here, and you can see the pod ips like so:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">kubectl get po <span class="nt">-o</span> wide
NAME                           READY     STATUS    RESTARTS   AGE       IP                NODE
frontend-88237173-jdfgg        1/1       Running   0          2h        192.168.175.197   host1
frontend-88237173-mzmjf        1/1       Running   0          4h        192.168.163.65    host2
frontend-88237173-z3ltv        1/1       Running   0          5h        192.168.173.195   host1
redis-master-343230949-2qrp7   1/1       Running   0          5h        192.168.90.131    host3
redis-slave-132015689-890b2    1/1       Running   0          5h        192.168.90.132    host1
redis-slave-132015689-k0rk5    1/1       Running   0          5h        192.168.175.196   host3</code></pre></figure>

<p>Now, in a working cluster, I should be able to get to any one of these IPs from my master:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ping -c 1 192.168.175.196</span>
PING 192.168.175.196 <span class="o">(</span>192.168.175.196<span class="o">)</span> 56<span class="o">(</span>84<span class="o">)</span> bytes of data.
64 bytes from 192.168.175.196: <span class="nv">icmp_seq</span><span class="o">=</span>1 <span class="nv">ttl</span><span class="o">=</span>63 <span class="nb">time</span><span class="o">=</span>0.433 ms

<span class="nt">---</span> 192.168.175.196 ping statistics <span class="nt">---</span>
1 packets transmitted, 1 received, 0% packet loss, <span class="nb">time </span>0ms
rtt min/avg/max/mdev <span class="o">=</span> 0.433/0.433/0.433/0.000 ms</code></pre></figure>

<p><em>if this doesn’t work from any node in your cluster, something is probably wrong</em></p>

<p>Similarly, you should be able to enter another pod and ping across pods:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ping -c 1 192.168.90.131</span>
PING 192.168.90.131 <span class="o">(</span>192.168.90.131<span class="o">)</span>: 48 data bytes
56 bytes from 192.168.90.131: <span class="nv">icmp_seq</span><span class="o">=</span>0 <span class="nv">ttl</span><span class="o">=</span>62 <span class="nb">time</span><span class="o">=</span>0.358 ms
<span class="nt">---</span> 192.168.90.131 ping statistics <span class="nt">---</span>
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max/stddev <span class="o">=</span> 0.358/0.358/0.358/0.000 ms</code></pre></figure>

<p>This fulfills the fundamental requirements of Kubernetes, and you know things are working. If this isn’t working, you need to get troubleshooting as to why.</p>

<p>Now, with flannel, this is all abstracted away from you, and it’s difficult to decipher. Some troubleshooting tips I’d recommend:</p>

<ul>
  <li>Make sure <code class="language-plaintext highlighter-rouge">flannel0</code> actually exists, and check the flannel logs</li>
  <li>Break out <code class="language-plaintext highlighter-rouge">tcpdump</code> with <code class="language-plaintext highlighter-rouge">tcpdump -vv icmp</code> and check the icmp request are arriving and leaving the nodes correctly.</li>
</ul>

<p>With Calico, this is much easier to debug (in my opinion) and I’ll detail some troubleshooting exercises in the next post.</p>

<h2 id="a-quick-note-about-services">A quick note about services</h2>

<p>One thing that I got confused about when I started with kubernetes is, why can’t I ping service IPs?</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ping -c 1 kubernetes.default</span>
PING kubernetes.default.svc.cluster.local <span class="o">(</span>10.96.0.1<span class="o">)</span>: 48 data bytes
<span class="nt">---</span> kubernetes.default.svc.cluster.local ping statistics <span class="nt">---</span>
1 packets transmitted, 0 packets received, 100% packet loss</code></pre></figure>

<p>The reason for this is actually quite simple - they don’t <em>technically</em> exist!</p>

<h3 id="kube-proxy">kube-proxy</h3>

<p>All the services in a cluster are handled by <a href="https://kubernetes.io/docs/admin/kube-proxy/">kube-proxy</a>. kube-proxy runs on every node in the cluster, and what it does it write <code class="language-plaintext highlighter-rouge">iptables</code> rules for each service. You can see this when you run <code class="language-plaintext highlighter-rouge">iptables-save</code>:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nt">-A</span> KUBE-SERVICES <span class="nt">-d</span> 10.107.179.200/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/redis-master: cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 6379 <span class="nt">-j</span> KUBE-SVC-7GF4BJM3Z6CMNVML
<span class="nt">-A</span> KUBE-SERVICES <span class="o">!</span> <span class="nt">-s</span> 192.168.0.0/16 <span class="nt">-d</span> 10.98.90.196/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/redis-slave: cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 6379 <span class="nt">-j</span> KUBE-MARK-MASQ
<span class="nt">-A</span> KUBE-SERVICES <span class="nt">-d</span> 10.98.90.196/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/redis-slave: cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 6379 <span class="nt">-j</span> KUBE-SVC-AGR3D4D4FQNH4O33
<span class="nt">-A</span> KUBE-SERVICES <span class="o">!</span> <span class="nt">-s</span> 192.168.0.0/16 <span class="nt">-d</span> 10.99.237.90/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/frontend: cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 80 <span class="nt">-j</span> KUBE-MARK-MASQ
<span class="nt">-A</span> KUBE-SERVICES <span class="nt">-d</span> 10.99.237.90/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/frontend: cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 80 <span class="nt">-j</span> KUBE-SVC-GYQQTB6TY565JPRW
<span class="nt">-A</span> KUBE-SERVICES <span class="o">!</span> <span class="nt">-s</span> 192.168.0.0/16 <span class="nt">-d</span> 10.96.0.1/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/kubernetes:https cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 443 <span class="nt">-j</span> KUBE-MARK-MASQ
<span class="nt">-A</span> KUBE-SERVICES <span class="nt">-d</span> 10.96.0.1/32 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/kubernetes:https cluster IP"</span> <span class="nt">-m</span> tcp <span class="nt">--dport</span> 443 <span class="nt">-j</span> KUBE-SVC-NPX46M4PTMTKRN6Y
<span class="nt">-A</span> KUBE-SERVICES <span class="o">!</span> <span class="nt">-s</span> 192.168.0.0/16 <span class="nt">-d</span> 10.96.0.10/32 <span class="nt">-p</span> udp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"kube-system/kube-dns:dns cluster IP"</span> <span class="nt">-m</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> KUBE-MARK-MASQ
<span class="nt">-A</span> KUBE-SERVICES <span class="nt">-d</span> 10.96.0.10/32 <span class="nt">-p</span> udp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"kube-system/kube-dns:dns cluster IP"</span> <span class="nt">-m</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> KUBE-SVC-TCOU7JCQXEZGVUNU</code></pre></figure>

<p>This is just a taste of what you’ll see, but essentially, these iptables rules manage the traffic towards the service IPs. They don’t actually <em>have</em> any rules for ICMP, because it’s not needed.</p>

<p>So, if from host you try hit a service on a <code class="language-plaintext highlighter-rouge">TCP</code> port, you’ll see it works!</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># curl -k https://10.96.0.1</span>
Unauthorized</code></pre></figure>

<p>Don’t be fooled on the Unauthorized message here, it’s just the kubernetes API rejecting unauthorized requests. Iptables handily translated the request off towards the node the pod is running on, and made it hit the IP for you. Here’s the <code class="language-plaintext highlighter-rouge">iptables</code> rule:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nt">-A</span> KUBE-SEP-EHCIXHWU3R7SVNN2 <span class="nt">-s</span> 172.29.132.126/32 <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/kubernetes:https"</span> <span class="nt">-j</span> KUBE-MARK-MASQ
<span class="nt">-A</span> KUBE-SEP-EHCIXHWU3R7SVNN2 <span class="nt">-p</span> tcp <span class="nt">-m</span> comment <span class="nt">--comment</span> <span class="s2">"default/kubernetes:https"</span> <span class="nt">-m</span> recent <span class="nt">--set</span> <span class="nt">--name</span> KUBE-SEP-EHCIXHWU3R7SVNN2 <span class="nt">--mask</span> 255.255.255.255 <span class="nt">--rsource</span> <span class="nt">-m</span> tcp <span class="nt">-j</span> DNAT <span class="nt">--to-destination</span> 172.29.132.126:6443</code></pre></figure>

<p>Simple!</p>

<h1 id="wrap-up">Wrap up</h1>

<p>This should wrap up the basics of how kubernetes networking works, without going into the specifics of exactly what’s happening. In the next post, I’ll specifically cover <a href="https://projectcalico.org">Calico</a> and how it operates alongside kubernetes using the magic of routing to help your packets reach their destination.</p>

<br>

<div id="disqus_thread"></div>
<script>


var disqus_config = function () {
this.page.url = 'http://localhost:4000/assets/style.css';
this.page.identifier = '/blog/2017/02/15/kubernetes-networking-part1.html'; 
};

(function() {
var d = document, s = d.createElement('script');
s.src = 'https://.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            

<br>
<div class="about">
<div class="about__devider">*****</div>
<div class="about__text">
<br>
&#169 2021, Lee Briggs | <a href="https://github.com/ritijjain/pudhina-fresh">Pudhina Fresh</a> theme for Jekyll.
</div>
</div>

</div>
</body>
</html>